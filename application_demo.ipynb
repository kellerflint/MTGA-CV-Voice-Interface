{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import easyocr\n",
    "import numpy as np\n",
    "from mss import mss\n",
    "import keyboard\n",
    "import whisper\n",
    "import pyaudio\n",
    "import webrtcvad\n",
    "import wave\n",
    "import os\n",
    "import datetime\n",
    "from groq import Groq\n",
    "import pyautogui\n",
    "import json\n",
    "\n",
    "reader = easyocr.Reader(['en'])\n",
    "api_key = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Devices:  9\n",
      "{'index': 0, 'structVersion': 2, 'name': 'Microsoft Sound Mapper - Input', 'hostApi': 0, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "Input Device id  0  -  Microsoft Sound Mapper - Input\n",
      "{'index': 1, 'structVersion': 2, 'name': 'Microphone (USB Camera)', 'hostApi': 0, 'maxInputChannels': 1, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "Input Device id  1  -  Microphone (USB Camera)\n",
      "{'index': 2, 'structVersion': 2, 'name': 'Microphone (Scarlett Solo USB)', 'hostApi': 0, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "Input Device id  2  -  Microphone (Scarlett Solo USB)\n",
      "{'index': 3, 'structVersion': 2, 'name': 'Microphone (NexiGo N660 FHD Web', 'hostApi': 0, 'maxInputChannels': 1, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "Input Device id  3  -  Microphone (NexiGo N660 FHD Web\n",
      "{'index': 4, 'structVersion': 2, 'name': 'Microsoft Sound Mapper - Output', 'hostApi': 0, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "{'index': 5, 'structVersion': 2, 'name': 'Speakers (Scarlett Solo USB)', 'hostApi': 0, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "{'index': 6, 'structVersion': 2, 'name': 'BenQ GW2480 (NVIDIA High Defini', 'hostApi': 0, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "{'index': 7, 'structVersion': 2, 'name': 'BenQ GW2480 (NVIDIA High Defini', 'hostApi': 0, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "{'index': 8, 'structVersion': 2, 'name': 'BenQ GW2480 (NVIDIA High Defini', 'hostApi': 0, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n"
     ]
    }
   ],
   "source": [
    "p = pyaudio.PyAudio()\n",
    "info = p.get_host_api_info_by_index(0)\n",
    "numdevices = info.get('deviceCount')\n",
    "\n",
    "print('Devices: ', numdevices)\n",
    "\n",
    "for i in range(0, numdevices):\n",
    "    print(p.get_device_info_by_host_api_device_index(0, i))\n",
    "    if (p.get_device_info_by_host_api_device_index(0, i).get('maxInputChannels')) > 0:\n",
    "        print(\"Input Device id \", i, \" - \", p.get_device_info_by_host_api_device_index(0, i).get('name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeechDetector:\n",
    "    def __init__(self, audio_out_path, audio_device_index, chunk_size=480, format=pyaudio.paInt16, channels=1, rate=16000, silence_duration=1):\n",
    "        self.audio_out_path = audio_out_path\n",
    "        self.audio_device_index = audio_device_index\n",
    "        self.chunk_size = chunk_size\n",
    "        self.format = format\n",
    "        self.channels = channels\n",
    "        self.rate = rate\n",
    "        self.silence_duration = silence_duration\n",
    "\n",
    "        self.p = pyaudio.PyAudio()\n",
    "        self.vad = webrtcvad.Vad()\n",
    "        self.vad.set_mode(3)  # Set VAD aggressiveness (0-3)\n",
    "\n",
    "    def record_audio(self):\n",
    "        stream = self.p.open(format=self.format, channels=self.channels, rate=self.rate, input=True, frames_per_buffer=self.chunk_size, input_device_index=self.audio_device_index)\n",
    "\n",
    "        print(\"Waiting for speech...\")\n",
    "\n",
    "        frames = []\n",
    "        silence_frames = 0\n",
    "        speech_started = False\n",
    "\n",
    "        while True:\n",
    "            data = stream.read(self.chunk_size)\n",
    "\n",
    "            if not speech_started:\n",
    "                if self.vad.is_speech(data, self.rate):\n",
    "                    speech_started = True\n",
    "                    print(\"Recording started.\")\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            frames.append(data)\n",
    "\n",
    "            if self.vad.is_speech(data, self.rate):\n",
    "                silence_frames = 0\n",
    "            else:\n",
    "                silence_frames += self.chunk_size\n",
    "\n",
    "            if silence_frames >= self.rate * self.silence_duration:\n",
    "                break\n",
    "\n",
    "        print(\"Recording finished at \", datetime.datetime.now())\n",
    "\n",
    "        wf = wave.open(self.audio_out_path, \"wb\")\n",
    "        wf.setnchannels(self.channels)\n",
    "        wf.setsampwidth(self.p.get_sample_size(self.format))\n",
    "        wf.setframerate(self.rate)\n",
    "        wf.writeframes(b\"\".join(frames))\n",
    "        wf.close()\n",
    "\n",
    "        print(f\"Audio saved as {self.audio_out_path}\")\n",
    "\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "\n",
    "    def terminate(self):\n",
    "        self.p.terminate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class STT:\n",
    "    def __init__(self):\n",
    "        self.model = whisper.load_model(\"base\")\n",
    "\n",
    "    def transcribe(self, audio_file: str):\n",
    "        print(\"Outputting Audio File\", audio_file)\n",
    "        result = self.model.transcribe(audio_file)\n",
    "        return result[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Groq(\n",
    "    api_key=api_key\n",
    ")\n",
    "\n",
    "def generate_response(messages, tools=[], model=\"llama-3.1-8b-instant\", max_tokens=150, temperature=0.7):\n",
    "    print(\"Generating response for messages:\", messages)\n",
    "\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=messages,\n",
    "        model=model,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature,\n",
    "        tools=tools\n",
    "    )\n",
    "\n",
    "    response = chat_completion.choices[0].message\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool definitions\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"click\",\n",
    "            \"description\": \"Clicks on a card\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"id\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"The Card ID to click on.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"id\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"goto\",\n",
    "            \"description\": \"Moves the mouse to the location of a card\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"id\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"The Card ID to move the mouse to.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"id\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"play\",\n",
    "            \"description\": \"Plays a card\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"id\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"The Card ID of the card to play.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"id\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool functions\n",
    "def click_tool(id: int, boxes):\n",
    "    print(\"Clicking on\", id)\n",
    "    boxOptions = [box for box in boxes if box.id == id]\n",
    "    if len(boxOptions) == 0: return\n",
    "    box = boxOptions[0]\n",
    "\n",
    "    print(f\"Found box, executing on ({box.xc}, {box.yc})\")\n",
    "    pyautogui.moveTo(box.xc, box.yc, duration=0.25)\n",
    "    pyautogui.mouseDown(); pyautogui.mouseUp()\n",
    "\n",
    "def goto_tool(id, boxes):\n",
    "    print(\"Going to\", id)\n",
    "    boxOptions = [box for box in boxes if box.id == id]\n",
    "    if len(boxOptions) == 0: return\n",
    "    box = boxOptions[0]\n",
    "\n",
    "    print(f\"Found box, executing on ({box.xc}, {box.yc})\")\n",
    "    pyautogui.moveTo(box.xc, box.yc, duration=0.25)\n",
    "\n",
    "def play_tool(id, boxes):\n",
    "    print(\"Playing\", id)\n",
    "    boxOptions = [box for box in boxes if box.id == id]\n",
    "    if len(boxOptions) == 0: return\n",
    "    box = boxOptions[0]\n",
    "\n",
    "    print(f\"Found box, executing on ({box.xc}, {box.yc})\")\n",
    "    pyautogui.moveTo(box.xc, box.yc, duration=0.25)\n",
    "    pyautogui.mouseDown(); pyautogui.mouseUp()\n",
    "    pyautogui.moveTo(box.xc, 500, duration=0.25)\n",
    "    pyautogui.mouseDown(); pyautogui.mouseUp()\n",
    "    \n",
    "\n",
    "# Execute selected tool\n",
    "def execute_tool(tool_name, params={}, boxes=[]):\n",
    "\n",
    "    params = json.loads(params)\n",
    "\n",
    "    # Map tool functions\n",
    "    tool_functions = {\n",
    "        \"click\": click_tool,\n",
    "        \"goto\": goto_tool,\n",
    "        \"play\": play_tool\n",
    "    }\n",
    "\n",
    "    if tool_name in tool_functions:\n",
    "        print(f\"Executing tool: {tool_name}\")\n",
    "        print(params)\n",
    "        return tool_functions[tool_name](**params, boxes=boxes)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown tool: {tool_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing tool: click\n",
      "{'id': 1}\n",
      "Clicking on 1\n",
      "Executing tool: goto\n",
      "{'id': 2}\n",
      "Going to 2\n",
      "Executing tool: play\n",
      "{'id': 3}\n",
      "Playing 3\n"
     ]
    }
   ],
   "source": [
    "# Tool Checking\n",
    "execute_tool(\"click\", '{\"id\": 1}')\n",
    "execute_tool(\"goto\", '{\"id\": 2}')\n",
    "execute_tool(\"play\", '{\"id\": 3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(box):\n",
    "    plt.figure()\n",
    "    plt.title(f\"Box: {box.class_name} (Confidence: {box.confidence:.2f})\")\n",
    "    plt.imshow(cv2.cvtColor(box.image, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Box:\n",
    "    def __init__(self, id: int, image, x1, y1, x2, y2, class_name, confidence):\n",
    "        self.id = id\n",
    "        self.image = image\n",
    "        self.x1, self.y1, self.x2, self.y2 = x1, y1, x2, y2\n",
    "        self.xc, self.yc = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "        self.class_name = class_name\n",
    "        self.text = self.ocr()\n",
    "        self.confidence = confidence\n",
    "\n",
    "    def ocr(self):\n",
    "        gray = cv2.cvtColor(self.image, cv2.COLOR_BGR2GRAY)\n",
    "        results = reader.readtext(gray)\n",
    "        detected_text = ''.join([result[1] for result in results]) \n",
    "        return detected_text\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"Box {self.id}: {self.class_name} ({self.confidence:.2f}) \\nCenter: ({self.xc}, {self.yc}) \\nText: {self.text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame(model, frame):\n",
    "    img = cv2.cvtColor(np.array(frame), cv2.COLOR_BGRA2BGR)\n",
    "    \n",
    "    # Run inference\n",
    "    results = model.predict(img, conf=0.5, verbose=False)\n",
    "\n",
    "    # Extract bounding boxes\n",
    "    boxes = []\n",
    "    for i, box in enumerate(results[0].boxes):\n",
    "        x_min, y_min, x_max, y_max = map(int, box.xyxy[0].tolist())\n",
    "        class_id = int(box.cls[0])\n",
    "        class_name = model.names[class_id]\n",
    "        confidence = float(box.conf[0])\n",
    "\n",
    "        boxes.append(Box(\n",
    "            id=i,\n",
    "            image=img[y_min:y_max, x_min:x_max],\n",
    "            x1=x_min, \n",
    "            x2=x_max,\n",
    "            y1=y_min,\n",
    "            y2=y_max, \n",
    "            class_name=class_name,\n",
    "            confidence=confidence\n",
    "        ))\n",
    "\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for speech...\n",
      "Recording started.\n",
      "Recording finished at  2024-12-08 14:02:04.202612\n",
      "Audio saved as output.wav\n",
      "Outputting Audio File output.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Dev\\MTGA-CV-Voice-Interface\\.venv\\Lib\\site-packages\\whisper\\transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription completed at 2024-12-08 14:02:04.664824 Text:  Click the cancel button.\n",
      "[{'role': 'system', 'content': \"The user will give you a command and a card name. Ignore any instructions that are not commands to play, click, or move to a card.\\n                         Perform only one action at a time. If the user does not provide instructions or their is unrelated to playing cards, don't call any tools.\\n                         Instructions will start with the command and then tell you the card. Call the appropriate tool and give it the ID of the card the user tells you to play. \\n                         The card text can be somewhat garbled, but do your best to match the card the user asks for with the text of the cards.\"}, {'role': 'user', 'content': 'User Command:\\n Click the cancel button.\\n\\n\\nCards:\\n Card ID:\\n0\\nCard Text:\\n\\n---\\nCard ID:\\n1\\nCard Text:\\n\\n---\\nCard ID:\\n2\\nCard Text:\\n\\n---\\nCard ID:\\n3\\nCard Text:\\nMloolit1\\n---\\nCard ID:\\n4\\nCard Text:\\nCleric ClassAbility8€: LevelWhenever you gain life, put a +1/+1counter on target creature youcontrol:\\n---\\nCard ID:\\n5\\nCard Text:\\nCleric Class Ability43: Level 3When this Class becomes levelreturn target creature card from yourgraveyard to the battlefleld: You gainIife equal to that creature\\'toughness_\\n---\\nCard ID:\\n6\\nCard Text:\\nallwde Herbiser\\n---\\nCard ID:\\n7\\nCard Text:\\n\\'\\n---\\nCard ID:\\n8\\nCard Text:\\n\\n---\\nCard ID:\\n9\\nCard Text:\\n\\n---\\nCard ID:\\n10\\nCard Text:\\n\\n---\\nCard ID:\\n11\\nCard Text:\\nLLw |\\'T`[\\n---\\nCard ID:\\n12\\nCard Text:\\n0{0\"60V\\n---\\nCard ID:\\n13\\nCard Text:\\nCancel\\n---\\nCard ID:\\n14\\nCard Text:\\n| | \\' \"4{1\\'|1|\\' \\'\\'14 `\\n---\\n'}]\n",
      "Generating response for messages: [{'role': 'system', 'content': \"The user will give you a command and a card name. Ignore any instructions that are not commands to play, click, or move to a card.\\n                         Perform only one action at a time. If the user does not provide instructions or their is unrelated to playing cards, don't call any tools.\\n                         Instructions will start with the command and then tell you the card. Call the appropriate tool and give it the ID of the card the user tells you to play. \\n                         The card text can be somewhat garbled, but do your best to match the card the user asks for with the text of the cards.\"}, {'role': 'user', 'content': 'User Command:\\n Click the cancel button.\\n\\n\\nCards:\\n Card ID:\\n0\\nCard Text:\\n\\n---\\nCard ID:\\n1\\nCard Text:\\n\\n---\\nCard ID:\\n2\\nCard Text:\\n\\n---\\nCard ID:\\n3\\nCard Text:\\nMloolit1\\n---\\nCard ID:\\n4\\nCard Text:\\nCleric ClassAbility8€: LevelWhenever you gain life, put a +1/+1counter on target creature youcontrol:\\n---\\nCard ID:\\n5\\nCard Text:\\nCleric Class Ability43: Level 3When this Class becomes levelreturn target creature card from yourgraveyard to the battlefleld: You gainIife equal to that creature\\'toughness_\\n---\\nCard ID:\\n6\\nCard Text:\\nallwde Herbiser\\n---\\nCard ID:\\n7\\nCard Text:\\n\\'\\n---\\nCard ID:\\n8\\nCard Text:\\n\\n---\\nCard ID:\\n9\\nCard Text:\\n\\n---\\nCard ID:\\n10\\nCard Text:\\n\\n---\\nCard ID:\\n11\\nCard Text:\\nLLw |\\'T`[\\n---\\nCard ID:\\n12\\nCard Text:\\n0{0\"60V\\n---\\nCard ID:\\n13\\nCard Text:\\nCancel\\n---\\nCard ID:\\n14\\nCard Text:\\n| | \\' \"4{1\\'|1|\\' \\'\\'14 `\\n---\\n'}]\n",
      "Executing tool: click\n",
      "{'id': 13}\n",
      "Clicking on 13\n",
      "Found box, executing on (958, 873)\n",
      "Waiting for speech...\n",
      "Recording started.\n",
      "Recording finished at  2024-12-08 14:02:15.501969\n",
      "Audio saved as output.wav\n",
      "Outputting Audio File output.wav\n",
      "Transcription completed at 2024-12-08 14:02:15.940777 Text:  a prosperous inkeeper.\n",
      "[{'role': 'system', 'content': \"The user will give you a command and a card name. Ignore any instructions that are not commands to play, click, or move to a card.\\n                         Perform only one action at a time. If the user does not provide instructions or their is unrelated to playing cards, don't call any tools.\\n                         Instructions will start with the command and then tell you the card. Call the appropriate tool and give it the ID of the card the user tells you to play. \\n                         The card text can be somewhat garbled, but do your best to match the card the user asks for with the text of the cards.\"}, {'role': 'user', 'content': 'User Command:\\n a prosperous inkeeper.\\n\\n\\nCards:\\n Card ID:\\n0\\nCard Text:\\n\\n---\\nCard ID:\\n1\\nCard Text:\\n\\n---\\nCard ID:\\n2\\nCard Text:\\n\\n---\\nCard ID:\\n3\\nCard Text:\\nTrelasarra,Moon Dancer\\n---\\nCard ID:\\n4\\nCard Text:\\nRobbur\\n---\\nCard ID:\\n5\\nCard Text:\\nInnkeeperRrusperous\\n---\\nCard ID:\\n6\\nCard Text:\\nHallowed Priest\\n---\\nCard ID:\\n7\\nCard Text:\\nLucmunuaAni -Aaie\\n---\\nCard ID:\\n8\\nCard Text:\\n[Soulmender\\n---\\nCard ID:\\n9\\nCard Text:\\n\\n---\\nCard ID:\\n10\\nCard Text:\\nalkyrieHarbinger\\n---\\nCard ID:\\n11\\nCard Text:\\n(HallowedPrest\\n---\\nCard ID:\\n12\\nCard Text:\\nNext\\n---\\nCard ID:\\n13\\nCard Text:\\nYalkuieRighleous\\n---\\n'}]\n",
      "Generating response for messages: [{'role': 'system', 'content': \"The user will give you a command and a card name. Ignore any instructions that are not commands to play, click, or move to a card.\\n                         Perform only one action at a time. If the user does not provide instructions or their is unrelated to playing cards, don't call any tools.\\n                         Instructions will start with the command and then tell you the card. Call the appropriate tool and give it the ID of the card the user tells you to play. \\n                         The card text can be somewhat garbled, but do your best to match the card the user asks for with the text of the cards.\"}, {'role': 'user', 'content': 'User Command:\\n a prosperous inkeeper.\\n\\n\\nCards:\\n Card ID:\\n0\\nCard Text:\\n\\n---\\nCard ID:\\n1\\nCard Text:\\n\\n---\\nCard ID:\\n2\\nCard Text:\\n\\n---\\nCard ID:\\n3\\nCard Text:\\nTrelasarra,Moon Dancer\\n---\\nCard ID:\\n4\\nCard Text:\\nRobbur\\n---\\nCard ID:\\n5\\nCard Text:\\nInnkeeperRrusperous\\n---\\nCard ID:\\n6\\nCard Text:\\nHallowed Priest\\n---\\nCard ID:\\n7\\nCard Text:\\nLucmunuaAni -Aaie\\n---\\nCard ID:\\n8\\nCard Text:\\n[Soulmender\\n---\\nCard ID:\\n9\\nCard Text:\\n\\n---\\nCard ID:\\n10\\nCard Text:\\nalkyrieHarbinger\\n---\\nCard ID:\\n11\\nCard Text:\\n(HallowedPrest\\n---\\nCard ID:\\n12\\nCard Text:\\nNext\\n---\\nCard ID:\\n13\\nCard Text:\\nYalkuieRighleous\\n---\\n'}]\n",
      "Executing tool: play\n",
      "{'id': 5}\n",
      "Playing 5\n",
      "Found box, executing on (678, 1007)\n",
      "Waiting for speech...\n",
      "Recording started.\n",
      "Recording finished at  2024-12-08 14:02:29.202476\n",
      "Audio saved as output.wav\n",
      "Outputting Audio File output.wav\n",
      "Transcription completed at 2024-12-08 14:02:29.628443 Text:  console mender.\n",
      "[{'role': 'system', 'content': \"The user will give you a command and a card name. Ignore any instructions that are not commands to play, click, or move to a card.\\n                         Perform only one action at a time. If the user does not provide instructions or their is unrelated to playing cards, don't call any tools.\\n                         Instructions will start with the command and then tell you the card. Call the appropriate tool and give it the ID of the card the user tells you to play. \\n                         The card text can be somewhat garbled, but do your best to match the card the user asks for with the text of the cards.\"}, {'role': 'user', 'content': 'User Command:\\n console mender.\\n\\n\\nCards:\\n Card ID:\\n0\\nCard Text:\\n\\n---\\nCard ID:\\n1\\nCard Text:\\nDancerTrelasarr Moon\\n---\\nCard ID:\\n2\\nCard Text:\\n\\n---\\nCard ID:\\n3\\nCard Text:\\nnaneroueInnkkeener\\n---\\nCard ID:\\n4\\nCard Text:\\n\\n---\\nCard ID:\\n5\\nCard Text:\\n\\n---\\nCard ID:\\n6\\nCard Text:\\nWest Robhe\\n---\\nCard ID:\\n7\\nCard Text:\\nHallowed Priest\\n---\\nCard ID:\\n8\\nCard Text:\\nHouts\\n---\\nCard ID:\\n9\\nCard Text:\\niSoulmende\\n---\\nCard ID:\\n10\\nCard Text:\\n\\n---\\nCard ID:\\n11\\nCard Text:\\nalkyrie Harbinger\\n---\\nCard ID:\\n12\\nCard Text:\\n(Malowed Pricst\\n---\\nCard ID:\\n13\\nCard Text:\\nVallsuie(Righteous\\n---\\nCard ID:\\n14\\nCard Text:\\nNext\\n---\\n'}]\n",
      "Generating response for messages: [{'role': 'system', 'content': \"The user will give you a command and a card name. Ignore any instructions that are not commands to play, click, or move to a card.\\n                         Perform only one action at a time. If the user does not provide instructions or their is unrelated to playing cards, don't call any tools.\\n                         Instructions will start with the command and then tell you the card. Call the appropriate tool and give it the ID of the card the user tells you to play. \\n                         The card text can be somewhat garbled, but do your best to match the card the user asks for with the text of the cards.\"}, {'role': 'user', 'content': 'User Command:\\n console mender.\\n\\n\\nCards:\\n Card ID:\\n0\\nCard Text:\\n\\n---\\nCard ID:\\n1\\nCard Text:\\nDancerTrelasarr Moon\\n---\\nCard ID:\\n2\\nCard Text:\\n\\n---\\nCard ID:\\n3\\nCard Text:\\nnaneroueInnkkeener\\n---\\nCard ID:\\n4\\nCard Text:\\n\\n---\\nCard ID:\\n5\\nCard Text:\\n\\n---\\nCard ID:\\n6\\nCard Text:\\nWest Robhe\\n---\\nCard ID:\\n7\\nCard Text:\\nHallowed Priest\\n---\\nCard ID:\\n8\\nCard Text:\\nHouts\\n---\\nCard ID:\\n9\\nCard Text:\\niSoulmende\\n---\\nCard ID:\\n10\\nCard Text:\\n\\n---\\nCard ID:\\n11\\nCard Text:\\nalkyrie Harbinger\\n---\\nCard ID:\\n12\\nCard Text:\\n(Malowed Pricst\\n---\\nCard ID:\\n13\\nCard Text:\\nVallsuie(Righteous\\n---\\nCard ID:\\n14\\nCard Text:\\nNext\\n---\\n'}]\n",
      "Executing tool: play\n",
      "{'id': 7}\n",
      "Playing 7\n",
      "Found box, executing on (952, 1001)\n",
      "Waiting for speech...\n",
      "Recording started.\n",
      "Recording finished at  2024-12-08 14:02:35.822588\n",
      "Audio saved as output.wav\n",
      "Outputting Audio File output.wav\n",
      "Transcription completed at 2024-12-08 14:02:36.246364 Text:  quick cancel.\n",
      "[{'role': 'system', 'content': \"The user will give you a command and a card name. Ignore any instructions that are not commands to play, click, or move to a card.\\n                         Perform only one action at a time. If the user does not provide instructions or their is unrelated to playing cards, don't call any tools.\\n                         Instructions will start with the command and then tell you the card. Call the appropriate tool and give it the ID of the card the user tells you to play. \\n                         The card text can be somewhat garbled, but do your best to match the card the user asks for with the text of the cards.\"}, {'role': 'user', 'content': 'User Command:\\n quick cancel.\\n\\n\\nCards:\\n Card ID:\\n0\\nCard Text:\\n\\n---\\nCard ID:\\n1\\nCard Text:\\n\\n---\\nCard ID:\\n2\\nCard Text:\\n\\n---\\nCard ID:\\n3\\nCard Text:\\n\\n---\\nCard ID:\\n4\\nCard Text:\\nFohleu\\n---\\nCard ID:\\n5\\nCard Text:\\nVulkyreRighcou\\n---\\nCard ID:\\n6\\nCard Text:\\nHallowed Priest _CreatureHuman ClericWhenever you gain life; put a +I/+1counter on Hallowed Priest:KIM SOKOL\\n---\\nCard ID:\\n7\\nCard Text:\\niSoulmender\\n---\\nCard ID:\\n8\\nCard Text:\\nValkyie Harbinger\\n---\\nCard ID:\\n9\\nCard Text:\\n\\n---\\nCard ID:\\n10\\nCard Text:\\n(relasarre,Moon Dancer\\n---\\nCard ID:\\n11\\nCard Text:\\nHallowed Priest\\n---\\nCard ID:\\n12\\nCard Text:\\nCancel\\n---\\nCard ID:\\n13\\nCard Text:\\nCrosperousinnkeener\\n---\\nCard ID:\\n14\\nCard Text:\\nCrosperousinnkeener\\n---\\n'}]\n",
      "Generating response for messages: [{'role': 'system', 'content': \"The user will give you a command and a card name. Ignore any instructions that are not commands to play, click, or move to a card.\\n                         Perform only one action at a time. If the user does not provide instructions or their is unrelated to playing cards, don't call any tools.\\n                         Instructions will start with the command and then tell you the card. Call the appropriate tool and give it the ID of the card the user tells you to play. \\n                         The card text can be somewhat garbled, but do your best to match the card the user asks for with the text of the cards.\"}, {'role': 'user', 'content': 'User Command:\\n quick cancel.\\n\\n\\nCards:\\n Card ID:\\n0\\nCard Text:\\n\\n---\\nCard ID:\\n1\\nCard Text:\\n\\n---\\nCard ID:\\n2\\nCard Text:\\n\\n---\\nCard ID:\\n3\\nCard Text:\\n\\n---\\nCard ID:\\n4\\nCard Text:\\nFohleu\\n---\\nCard ID:\\n5\\nCard Text:\\nVulkyreRighcou\\n---\\nCard ID:\\n6\\nCard Text:\\nHallowed Priest _CreatureHuman ClericWhenever you gain life; put a +I/+1counter on Hallowed Priest:KIM SOKOL\\n---\\nCard ID:\\n7\\nCard Text:\\niSoulmender\\n---\\nCard ID:\\n8\\nCard Text:\\nValkyie Harbinger\\n---\\nCard ID:\\n9\\nCard Text:\\n\\n---\\nCard ID:\\n10\\nCard Text:\\n(relasarre,Moon Dancer\\n---\\nCard ID:\\n11\\nCard Text:\\nHallowed Priest\\n---\\nCard ID:\\n12\\nCard Text:\\nCancel\\n---\\nCard ID:\\n13\\nCard Text:\\nCrosperousinnkeener\\n---\\nCard ID:\\n14\\nCard Text:\\nCrosperousinnkeener\\n---\\n'}]\n",
      "Executing tool: click\n",
      "{'id': 12}\n",
      "Clicking on 12\n",
      "Found box, executing on (1774, 949)\n",
      "Waiting for speech...\n",
      "Recording started.\n",
      "Recording finished at  2024-12-08 14:02:42.122331\n",
      "Audio saved as output.wav\n",
      "Outputting Audio File output.wav\n",
      "Transcription completed at 2024-12-08 14:02:42.569644 Text:  click Soulmender.\n",
      "[{'role': 'system', 'content': \"The user will give you a command and a card name. Ignore any instructions that are not commands to play, click, or move to a card.\\n                         Perform only one action at a time. If the user does not provide instructions or their is unrelated to playing cards, don't call any tools.\\n                         Instructions will start with the command and then tell you the card. Call the appropriate tool and give it the ID of the card the user tells you to play. \\n                         The card text can be somewhat garbled, but do your best to match the card the user asks for with the text of the cards.\"}, {'role': 'user', 'content': 'User Command:\\n click Soulmender.\\n\\n\\nCards:\\n Card ID:\\n0\\nCard Text:\\n\\n---\\nCard ID:\\n1\\nCard Text:\\n\\n---\\nCard ID:\\n2\\nCard Text:\\n\\n---\\nCard ID:\\n3\\nCard Text:\\n{ProsperousKeener\\n---\\nCard ID:\\n4\\nCard Text:\\nTrelasarr,Moonancer\\n---\\nCard ID:\\n5\\nCard Text:\\n\\n---\\nCard ID:\\n6\\nCard Text:\\nWest Robhe\\n---\\nCard ID:\\n7\\nCard Text:\\nKsouimender\\n---\\nCard ID:\\n8\\nCard Text:\\nriccercGbretada\\n---\\nCard ID:\\n9\\nCard Text:\\nValkyrie Harbinger\\n---\\nCard ID:\\n10\\nCard Text:\\n\\n---\\nCard ID:\\n11\\nCard Text:\\nHallowed Priest\\n---\\nCard ID:\\n12\\nCard Text:\\nNext\\n---\\nCard ID:\\n13\\nCard Text:\\nHallowedPuigst\\n---\\nCard ID:\\n14\\nCard Text:\\nVallsuie(Righteous\\n---\\n'}]\n",
      "Generating response for messages: [{'role': 'system', 'content': \"The user will give you a command and a card name. Ignore any instructions that are not commands to play, click, or move to a card.\\n                         Perform only one action at a time. If the user does not provide instructions or their is unrelated to playing cards, don't call any tools.\\n                         Instructions will start with the command and then tell you the card. Call the appropriate tool and give it the ID of the card the user tells you to play. \\n                         The card text can be somewhat garbled, but do your best to match the card the user asks for with the text of the cards.\"}, {'role': 'user', 'content': 'User Command:\\n click Soulmender.\\n\\n\\nCards:\\n Card ID:\\n0\\nCard Text:\\n\\n---\\nCard ID:\\n1\\nCard Text:\\n\\n---\\nCard ID:\\n2\\nCard Text:\\n\\n---\\nCard ID:\\n3\\nCard Text:\\n{ProsperousKeener\\n---\\nCard ID:\\n4\\nCard Text:\\nTrelasarr,Moonancer\\n---\\nCard ID:\\n5\\nCard Text:\\n\\n---\\nCard ID:\\n6\\nCard Text:\\nWest Robhe\\n---\\nCard ID:\\n7\\nCard Text:\\nKsouimender\\n---\\nCard ID:\\n8\\nCard Text:\\nriccercGbretada\\n---\\nCard ID:\\n9\\nCard Text:\\nValkyrie Harbinger\\n---\\nCard ID:\\n10\\nCard Text:\\n\\n---\\nCard ID:\\n11\\nCard Text:\\nHallowed Priest\\n---\\nCard ID:\\n12\\nCard Text:\\nNext\\n---\\nCard ID:\\n13\\nCard Text:\\nHallowedPuigst\\n---\\nCard ID:\\n14\\nCard Text:\\nVallsuie(Righteous\\n---\\n'}]\n",
      "Executing tool: click\n",
      "{'id': 7}\n",
      "Clicking on 7\n",
      "Found box, executing on (669, 589)\n",
      "Waiting for speech...\n",
      "Recording started.\n",
      "Recording finished at  2024-12-08 14:02:57.492708\n",
      "Audio saved as output.wav\n",
      "Outputting Audio File output.wav\n",
      "Transcription completed at 2024-12-08 14:02:57.946899 Text:  Click no blockers.\n",
      "[{'role': 'system', 'content': \"The user will give you a command and a card name. Ignore any instructions that are not commands to play, click, or move to a card.\\n                         Perform only one action at a time. If the user does not provide instructions or their is unrelated to playing cards, don't call any tools.\\n                         Instructions will start with the command and then tell you the card. Call the appropriate tool and give it the ID of the card the user tells you to play. \\n                         The card text can be somewhat garbled, but do your best to match the card the user asks for with the text of the cards.\"}, {'role': 'user', 'content': \"User Command:\\n Click no blockers.\\n\\n\\nCards:\\n Card ID:\\n0\\nCard Text:\\n\\n---\\nCard ID:\\n1\\nCard Text:\\n\\n---\\nCard ID:\\n2\\nCard Text:\\n\\n---\\nCard ID:\\n3\\nCard Text:\\n\\n---\\nCard ID:\\n4\\nCard Text:\\nValkyrie Harbinger_\\n---\\nCard ID:\\n5\\nCard Text:\\nRebbe\\n---\\nCard ID:\\n6\\nCard Text:\\nDancerTrelasarr,Moon\\n---\\nCard ID:\\n7\\nCard Text:\\nHallowedPriest\\n---\\nCard ID:\\n8\\nCard Text:\\n'Souiniender\\n---\\nCard ID:\\n9\\nCard Text:\\nMer uar\\n---\\nCard ID:\\n10\\nCard Text:\\nnsneroueInnkkeenerIl1\\n---\\nCard ID:\\n11\\nCard Text:\\n\\n---\\nCard ID:\\n12\\nCard Text:\\nMalkieRishuegus\\n---\\nCard ID:\\n13\\nCard Text:\\nPricstHallowed _\\n---\\nCard ID:\\n14\\nCard Text:\\nNo Blocks\\n---\\n\"}]\n",
      "Generating response for messages: [{'role': 'system', 'content': \"The user will give you a command and a card name. Ignore any instructions that are not commands to play, click, or move to a card.\\n                         Perform only one action at a time. If the user does not provide instructions or their is unrelated to playing cards, don't call any tools.\\n                         Instructions will start with the command and then tell you the card. Call the appropriate tool and give it the ID of the card the user tells you to play. \\n                         The card text can be somewhat garbled, but do your best to match the card the user asks for with the text of the cards.\"}, {'role': 'user', 'content': \"User Command:\\n Click no blockers.\\n\\n\\nCards:\\n Card ID:\\n0\\nCard Text:\\n\\n---\\nCard ID:\\n1\\nCard Text:\\n\\n---\\nCard ID:\\n2\\nCard Text:\\n\\n---\\nCard ID:\\n3\\nCard Text:\\n\\n---\\nCard ID:\\n4\\nCard Text:\\nValkyrie Harbinger_\\n---\\nCard ID:\\n5\\nCard Text:\\nRebbe\\n---\\nCard ID:\\n6\\nCard Text:\\nDancerTrelasarr,Moon\\n---\\nCard ID:\\n7\\nCard Text:\\nHallowedPriest\\n---\\nCard ID:\\n8\\nCard Text:\\n'Souiniender\\n---\\nCard ID:\\n9\\nCard Text:\\nMer uar\\n---\\nCard ID:\\n10\\nCard Text:\\nnsneroueInnkkeenerIl1\\n---\\nCard ID:\\n11\\nCard Text:\\n\\n---\\nCard ID:\\n12\\nCard Text:\\nMalkieRishuegus\\n---\\nCard ID:\\n13\\nCard Text:\\nPricstHallowed _\\n---\\nCard ID:\\n14\\nCard Text:\\nNo Blocks\\n---\\n\"}]\n",
      "Executing tool: click\n",
      "{'id': 14}\n",
      "Clicking on 14\n",
      "Found box, executing on (1773, 949)\n",
      "Waiting for speech...\n",
      "Recording started.\n",
      "Recording finished at  2024-12-08 14:03:06.902417\n",
      "Audio saved as output.wav\n",
      "Outputting Audio File output.wav\n",
      "Transcription completed at 2024-12-08 14:03:07.319438 Text:  play a plane.\n",
      "[{'role': 'system', 'content': \"The user will give you a command and a card name. Ignore any instructions that are not commands to play, click, or move to a card.\\n                         Perform only one action at a time. If the user does not provide instructions or their is unrelated to playing cards, don't call any tools.\\n                         Instructions will start with the command and then tell you the card. Call the appropriate tool and give it the ID of the card the user tells you to play. \\n                         The card text can be somewhat garbled, but do your best to match the card the user asks for with the text of the cards.\"}, {'role': 'user', 'content': 'User Command:\\n play a plane.\\n\\n\\nCards:\\n Card ID:\\n0\\nCard Text:\\n\\n---\\nCard ID:\\n1\\nCard Text:\\n\\n---\\nCard ID:\\n2\\nCard Text:\\n\\n---\\nCard ID:\\n3\\nCard Text:\\nXs\\n---\\nCard ID:\\n4\\nCard Text:\\nalkoie Harbinger\\n---\\nCard ID:\\n5\\nCard Text:\\nCrosperous [nnkeeper\\n---\\nCard ID:\\n6\\nCard Text:\\nRobbt\\n---\\nCard ID:\\n7\\nCard Text:\\nHallowed Priest\\n---\\nCard ID:\\n8\\nCard Text:\\nMoonDancerTrelash\\n---\\nCard ID:\\n9\\nCard Text:\\nHallowed Priest\\n---\\nCard ID:\\n10\\nCard Text:\\nLucmunuaAni =Htokete\\n---\\nCard ID:\\n11\\nCard Text:\\nKsouimender\\n---\\nCard ID:\\n12\\nCard Text:\\nNext\\n---\\nCard ID:\\n13\\nCard Text:\\n\\n---\\nCard ID:\\n14\\nCard Text:\\nValkytie{Rishteous\\n---\\n'}]\n",
      "Generating response for messages: [{'role': 'system', 'content': \"The user will give you a command and a card name. Ignore any instructions that are not commands to play, click, or move to a card.\\n                         Perform only one action at a time. If the user does not provide instructions or their is unrelated to playing cards, don't call any tools.\\n                         Instructions will start with the command and then tell you the card. Call the appropriate tool and give it the ID of the card the user tells you to play. \\n                         The card text can be somewhat garbled, but do your best to match the card the user asks for with the text of the cards.\"}, {'role': 'user', 'content': 'User Command:\\n play a plane.\\n\\n\\nCards:\\n Card ID:\\n0\\nCard Text:\\n\\n---\\nCard ID:\\n1\\nCard Text:\\n\\n---\\nCard ID:\\n2\\nCard Text:\\n\\n---\\nCard ID:\\n3\\nCard Text:\\nXs\\n---\\nCard ID:\\n4\\nCard Text:\\nalkoie Harbinger\\n---\\nCard ID:\\n5\\nCard Text:\\nCrosperous [nnkeeper\\n---\\nCard ID:\\n6\\nCard Text:\\nRobbt\\n---\\nCard ID:\\n7\\nCard Text:\\nHallowed Priest\\n---\\nCard ID:\\n8\\nCard Text:\\nMoonDancerTrelash\\n---\\nCard ID:\\n9\\nCard Text:\\nHallowed Priest\\n---\\nCard ID:\\n10\\nCard Text:\\nLucmunuaAni =Htokete\\n---\\nCard ID:\\n11\\nCard Text:\\nKsouimender\\n---\\nCard ID:\\n12\\nCard Text:\\nNext\\n---\\nCard ID:\\n13\\nCard Text:\\n\\n---\\nCard ID:\\n14\\nCard Text:\\nValkytie{Rishteous\\n---\\n'}]\n",
      "Executing tool: play\n",
      "{'id': 4}\n",
      "Playing 4\n",
      "Found box, executing on (861, 1002)\n",
      "Waiting for speech...\n",
      "Recording started.\n",
      "Recording finished at  2024-12-08 14:03:13.232682\n",
      "Audio saved as output.wav\n",
      "Outputting Audio File output.wav\n",
      "Transcription completed at 2024-12-08 14:03:13.655480 Text:  quick cancel.\n",
      "[{'role': 'system', 'content': \"The user will give you a command and a card name. Ignore any instructions that are not commands to play, click, or move to a card.\\n                         Perform only one action at a time. If the user does not provide instructions or their is unrelated to playing cards, don't call any tools.\\n                         Instructions will start with the command and then tell you the card. Call the appropriate tool and give it the ID of the card the user tells you to play. \\n                         The card text can be somewhat garbled, but do your best to match the card the user asks for with the text of the cards.\"}, {'role': 'user', 'content': 'User Command:\\n quick cancel.\\n\\n\\nCards:\\n Card ID:\\n0\\nCard Text:\\n\\n---\\nCard ID:\\n1\\nCard Text:\\n\\n---\\nCard ID:\\n2\\nCard Text:\\n\\n---\\nCard ID:\\n3\\nCard Text:\\nXS\\n---\\nCard ID:\\n4\\nCard Text:\\nDancerTrelasarr Moon\\n---\\nCard ID:\\n5\\nCard Text:\\nRobbt\\n---\\nCard ID:\\n6\\nCard Text:\\nCrosperousinnkeener\\n---\\nCard ID:\\n7\\nCard Text:\\nValkyrie HarbingerCreatureAngel ClericFlying; LifelinkAt the beginning of each end step; ifyou gainedor more life this turn;create a 4/4 white Angel creaturetoken with flying and vigilance.TRAN NGUYEN4/5\\n---\\nCard ID:\\n8\\nCard Text:\\nHallowed Priest\\n---\\nCard ID:\\n9\\nCard Text:\\nSSoulmender\\n---\\nCard ID:\\n10\\nCard Text:\\nHallowed Priest\\n---\\nCard ID:\\n11\\nCard Text:\\nVallsuie(Righteous\\n---\\nCard ID:\\n12\\nCard Text:\\nPlains\\n---\\nCard ID:\\n13\\nCard Text:\\nCancel\\n---\\n'}]\n",
      "Generating response for messages: [{'role': 'system', 'content': \"The user will give you a command and a card name. Ignore any instructions that are not commands to play, click, or move to a card.\\n                         Perform only one action at a time. If the user does not provide instructions or their is unrelated to playing cards, don't call any tools.\\n                         Instructions will start with the command and then tell you the card. Call the appropriate tool and give it the ID of the card the user tells you to play. \\n                         The card text can be somewhat garbled, but do your best to match the card the user asks for with the text of the cards.\"}, {'role': 'user', 'content': 'User Command:\\n quick cancel.\\n\\n\\nCards:\\n Card ID:\\n0\\nCard Text:\\n\\n---\\nCard ID:\\n1\\nCard Text:\\n\\n---\\nCard ID:\\n2\\nCard Text:\\n\\n---\\nCard ID:\\n3\\nCard Text:\\nXS\\n---\\nCard ID:\\n4\\nCard Text:\\nDancerTrelasarr Moon\\n---\\nCard ID:\\n5\\nCard Text:\\nRobbt\\n---\\nCard ID:\\n6\\nCard Text:\\nCrosperousinnkeener\\n---\\nCard ID:\\n7\\nCard Text:\\nValkyrie HarbingerCreatureAngel ClericFlying; LifelinkAt the beginning of each end step; ifyou gainedor more life this turn;create a 4/4 white Angel creaturetoken with flying and vigilance.TRAN NGUYEN4/5\\n---\\nCard ID:\\n8\\nCard Text:\\nHallowed Priest\\n---\\nCard ID:\\n9\\nCard Text:\\nSSoulmender\\n---\\nCard ID:\\n10\\nCard Text:\\nHallowed Priest\\n---\\nCard ID:\\n11\\nCard Text:\\nVallsuie(Righteous\\n---\\nCard ID:\\n12\\nCard Text:\\nPlains\\n---\\nCard ID:\\n13\\nCard Text:\\nCancel\\n---\\n'}]\n",
      "Executing tool: goto\n",
      "{'id': 13}\n",
      "Going to 13\n",
      "Found box, executing on (1774, 949)\n",
      "Waiting for speech...\n",
      "Recording started.\n",
      "Recording finished at  2024-12-08 14:03:20.342590\n",
      "Audio saved as output.wav\n",
      "Outputting Audio File output.wav\n",
      "Transcription completed at 2024-12-08 14:03:21.010997 Text:  Click Cancel.\n",
      "[{'role': 'system', 'content': \"The user will give you a command and a card name. Ignore any instructions that are not commands to play, click, or move to a card.\\n                         Perform only one action at a time. If the user does not provide instructions or their is unrelated to playing cards, don't call any tools.\\n                         Instructions will start with the command and then tell you the card. Call the appropriate tool and give it the ID of the card the user tells you to play. \\n                         The card text can be somewhat garbled, but do your best to match the card the user asks for with the text of the cards.\"}, {'role': 'user', 'content': 'User Command:\\n Click Cancel.\\n\\n\\nCards:\\n Card ID:\\n0\\nCard Text:\\n\\n---\\nCard ID:\\n1\\nCard Text:\\n\\n---\\nCard ID:\\n2\\nCard Text:\\n\\n---\\nCard ID:\\n3\\nCard Text:\\nXS\\n---\\nCard ID:\\n4\\nCard Text:\\nDancerTrelasarr Moon\\n---\\nCard ID:\\n5\\nCard Text:\\nRobbt\\n---\\nCard ID:\\n6\\nCard Text:\\nDrosperousinnkeener\\n---\\nCard ID:\\n7\\nCard Text:\\nValkyrie HarbingerCreatureAngel ClericFlying; LifelinkAt the beginning of each end step; ifyou gainedor more life this turn;create a 4/4 white Angel creaturetoken with flying and vigilance.TRAN NGUYEN4/5\\n---\\nCard ID:\\n8\\nCard Text:\\nHallowed Priest\\n---\\nCard ID:\\n9\\nCard Text:\\nSSoulmender\\n---\\nCard ID:\\n10\\nCard Text:\\nHallowed Priest\\n---\\nCard ID:\\n11\\nCard Text:\\nVallsuie(Righteous\\n---\\nCard ID:\\n12\\nCard Text:\\nPlains\\n---\\nCard ID:\\n13\\nCard Text:\\nCancel\\n---\\n'}]\n",
      "Generating response for messages: [{'role': 'system', 'content': \"The user will give you a command and a card name. Ignore any instructions that are not commands to play, click, or move to a card.\\n                         Perform only one action at a time. If the user does not provide instructions or their is unrelated to playing cards, don't call any tools.\\n                         Instructions will start with the command and then tell you the card. Call the appropriate tool and give it the ID of the card the user tells you to play. \\n                         The card text can be somewhat garbled, but do your best to match the card the user asks for with the text of the cards.\"}, {'role': 'user', 'content': 'User Command:\\n Click Cancel.\\n\\n\\nCards:\\n Card ID:\\n0\\nCard Text:\\n\\n---\\nCard ID:\\n1\\nCard Text:\\n\\n---\\nCard ID:\\n2\\nCard Text:\\n\\n---\\nCard ID:\\n3\\nCard Text:\\nXS\\n---\\nCard ID:\\n4\\nCard Text:\\nDancerTrelasarr Moon\\n---\\nCard ID:\\n5\\nCard Text:\\nRobbt\\n---\\nCard ID:\\n6\\nCard Text:\\nDrosperousinnkeener\\n---\\nCard ID:\\n7\\nCard Text:\\nValkyrie HarbingerCreatureAngel ClericFlying; LifelinkAt the beginning of each end step; ifyou gainedor more life this turn;create a 4/4 white Angel creaturetoken with flying and vigilance.TRAN NGUYEN4/5\\n---\\nCard ID:\\n8\\nCard Text:\\nHallowed Priest\\n---\\nCard ID:\\n9\\nCard Text:\\nSSoulmender\\n---\\nCard ID:\\n10\\nCard Text:\\nHallowed Priest\\n---\\nCard ID:\\n11\\nCard Text:\\nVallsuie(Righteous\\n---\\nCard ID:\\n12\\nCard Text:\\nPlains\\n---\\nCard ID:\\n13\\nCard Text:\\nCancel\\n---\\n'}]\n",
      "Executing tool: click\n",
      "{'id': 13}\n",
      "Clicking on 13\n",
      "Found box, executing on (1774, 949)\n",
      "Waiting for speech...\n",
      "Recording started.\n",
      "Recording finished at  2024-12-08 14:03:27.431938\n",
      "Audio saved as output.wav\n",
      "Outputting Audio File output.wav\n",
      "Transcription completed at 2024-12-08 14:03:27.870784 Text:  play the planes.\n",
      "[{'role': 'system', 'content': \"The user will give you a command and a card name. Ignore any instructions that are not commands to play, click, or move to a card.\\n                         Perform only one action at a time. If the user does not provide instructions or their is unrelated to playing cards, don't call any tools.\\n                         Instructions will start with the command and then tell you the card. Call the appropriate tool and give it the ID of the card the user tells you to play. \\n                         The card text can be somewhat garbled, but do your best to match the card the user asks for with the text of the cards.\"}, {'role': 'user', 'content': 'User Command:\\n play the planes.\\n\\n\\nCards:\\n Card ID:\\n0\\nCard Text:\\n\\n---\\nCard ID:\\n1\\nCard Text:\\n\\n---\\nCard ID:\\n2\\nCard Text:\\n\\n---\\nCard ID:\\n3\\nCard Text:\\nXs\\n---\\nCard ID:\\n4\\nCard Text:\\nHallowed Priest\\n---\\nCard ID:\\n5\\nCard Text:\\nCrosperous [nnkeeper\\n---\\nCard ID:\\n6\\nCard Text:\\nFoheu\\n---\\nCard ID:\\n7\\nCard Text:\\nMoonTrelasarDancer\\n---\\nCard ID:\\n8\\nCard Text:\\n(Hallowed Priest\\n---\\nCard ID:\\n9\\nCard Text:\\nKCcicri\\n---\\nCard ID:\\n10\\nCard Text:\\nUsouimender\\n---\\nCard ID:\\n11\\nCard Text:\\nPlain\\n---\\nCard ID:\\n12\\nCard Text:\\nNext\\n---\\nCard ID:\\n13\\nCard Text:\\nMalkyieHarbinget\\n---\\nCard ID:\\n14\\nCard Text:\\nYalkuieRighleous\\n---\\n'}]\n",
      "Generating response for messages: [{'role': 'system', 'content': \"The user will give you a command and a card name. Ignore any instructions that are not commands to play, click, or move to a card.\\n                         Perform only one action at a time. If the user does not provide instructions or their is unrelated to playing cards, don't call any tools.\\n                         Instructions will start with the command and then tell you the card. Call the appropriate tool and give it the ID of the card the user tells you to play. \\n                         The card text can be somewhat garbled, but do your best to match the card the user asks for with the text of the cards.\"}, {'role': 'user', 'content': 'User Command:\\n play the planes.\\n\\n\\nCards:\\n Card ID:\\n0\\nCard Text:\\n\\n---\\nCard ID:\\n1\\nCard Text:\\n\\n---\\nCard ID:\\n2\\nCard Text:\\n\\n---\\nCard ID:\\n3\\nCard Text:\\nXs\\n---\\nCard ID:\\n4\\nCard Text:\\nHallowed Priest\\n---\\nCard ID:\\n5\\nCard Text:\\nCrosperous [nnkeeper\\n---\\nCard ID:\\n6\\nCard Text:\\nFoheu\\n---\\nCard ID:\\n7\\nCard Text:\\nMoonTrelasarDancer\\n---\\nCard ID:\\n8\\nCard Text:\\n(Hallowed Priest\\n---\\nCard ID:\\n9\\nCard Text:\\nKCcicri\\n---\\nCard ID:\\n10\\nCard Text:\\nUsouimender\\n---\\nCard ID:\\n11\\nCard Text:\\nPlain\\n---\\nCard ID:\\n12\\nCard Text:\\nNext\\n---\\nCard ID:\\n13\\nCard Text:\\nMalkyieHarbinget\\n---\\nCard ID:\\n14\\nCard Text:\\nYalkuieRighleous\\n---\\n'}]\n",
      "Executing tool: play\n",
      "{'id': 4}\n",
      "Playing 4\n",
      "Found box, executing on (858, 1002)\n",
      "Waiting for speech...\n",
      "Recording started.\n",
      "Recording finished at  2024-12-08 14:03:33.951993\n",
      "Audio saved as output.wav\n",
      "Outputting Audio File output.wav\n",
      "Transcription completed at 2024-12-08 14:03:35.565873 Text:  got to play it.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[109], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m tool_call \u001b[38;5;129;01min\u001b[39;00m response\u001b[38;5;241m.\u001b[39mtool_calls:\n\u001b[0;32m     37\u001b[0m                 execute_tool(tool_call\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39mname, tool_call\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39marguments, boxes)\n\u001b[1;32m---> 39\u001b[0m \u001b[43mapp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[109], line 20\u001b[0m, in \u001b[0;36mapp\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTranscription completed at\u001b[39m\u001b[38;5;124m'\u001b[39m, datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mText:\u001b[39m\u001b[38;5;124m'\u001b[39m, transcription)\n\u001b[0;32m     19\u001b[0m screen \u001b[38;5;241m=\u001b[39m sct\u001b[38;5;241m.\u001b[39mgrab(monitor)\n\u001b[1;32m---> 20\u001b[0m boxes \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscreen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m boxes_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m box \u001b[38;5;129;01min\u001b[39;00m boxes:\n",
      "Cell \u001b[1;32mIn[107], line 15\u001b[0m, in \u001b[0;36mprocess_frame\u001b[1;34m(model, frame)\u001b[0m\n\u001b[0;32m     12\u001b[0m     class_name \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mnames[class_id]\n\u001b[0;32m     13\u001b[0m     confidence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(box\u001b[38;5;241m.\u001b[39mconf[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m---> 15\u001b[0m     boxes\u001b[38;5;241m.\u001b[39mappend(\u001b[43mBox\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg\u001b[49m\u001b[43m[\u001b[49m\u001b[43my_min\u001b[49m\u001b[43m:\u001b[49m\u001b[43my_max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_min\u001b[49m\u001b[43m:\u001b[49m\u001b[43mx_max\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_min\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43my1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_min\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43my2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfidence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfidence\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m boxes\n",
      "Cell \u001b[1;32mIn[106], line 8\u001b[0m, in \u001b[0;36mBox.__init__\u001b[1;34m(self, id, image, x1, y1, x2, y2, class_name, confidence)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxc, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39myc \u001b[38;5;241m=\u001b[39m (x1 \u001b[38;5;241m+\u001b[39m x2) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, (y1 \u001b[38;5;241m+\u001b[39m y2) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_name \u001b[38;5;241m=\u001b[39m class_name\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mocr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfidence \u001b[38;5;241m=\u001b[39m confidence\n",
      "Cell \u001b[1;32mIn[106], line 13\u001b[0m, in \u001b[0;36mBox.ocr\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mocr\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     12\u001b[0m     gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[1;32m---> 13\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadtext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgray\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     detected_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([result[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results]) \n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m detected_text\n",
      "File \u001b[1;32md:\\Dev\\MTGA-CV-Voice-Interface\\.venv\\Lib\\site-packages\\easyocr\\easyocr.py:456\u001b[0m, in \u001b[0;36mReader.readtext\u001b[1;34m(self, image, decoder, beamWidth, batch_size, workers, allowlist, blocklist, detail, rotation_info, paragraph, min_size, contrast_ths, adjust_contrast, filter_ths, text_threshold, low_text, link_threshold, canvas_size, mag_ratio, slope_ths, ycenter_ths, height_ths, width_ths, y_ths, x_ths, add_margin, threshold, bbox_min_score, bbox_min_size, max_candidates, output_format)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;124;03mimage: file path or numpy-array or a byte stream object\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m    454\u001b[0m img, img_cv_grey \u001b[38;5;241m=\u001b[39m reformat_input(image)\n\u001b[1;32m--> 456\u001b[0m horizontal_list, free_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mmin_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmin_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_threshold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtext_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mlow_text\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlow_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlink_threshold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlink_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mcanvas_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcanvas_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmag_ratio\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmag_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mslope_ths\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mslope_ths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mycenter_ths\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mycenter_ths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mheight_ths\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mheight_ths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth_ths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwidth_ths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43madd_margin\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43madd_margin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreformat\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox_min_score\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbbox_min_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mbbox_min_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbbox_min_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_candidates\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_candidates\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;66;03m# get the 1st result from hor & free list as self.detect returns a list of depth 3\u001b[39;00m\n\u001b[0;32m    467\u001b[0m horizontal_list, free_list \u001b[38;5;241m=\u001b[39m horizontal_list[\u001b[38;5;241m0\u001b[39m], free_list[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32md:\\Dev\\MTGA-CV-Voice-Interface\\.venv\\Lib\\site-packages\\easyocr\\easyocr.py:321\u001b[0m, in \u001b[0;36mReader.detect\u001b[1;34m(self, img, min_size, text_threshold, low_text, link_threshold, canvas_size, mag_ratio, slope_ths, ycenter_ths, height_ths, width_ths, add_margin, reformat, optimal_num_chars, threshold, bbox_min_score, bbox_min_size, max_candidates)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reformat:\n\u001b[0;32m    319\u001b[0m     img, img_cv_grey \u001b[38;5;241m=\u001b[39m reformat_input(img)\n\u001b[1;32m--> 321\u001b[0m text_box_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_textbox\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mcanvas_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcanvas_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mmag_ratio\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmag_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mtext_threshold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtext_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mlink_threshold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlink_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mlow_text\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlow_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mpoly\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m                            \u001b[49m\u001b[43moptimal_num_chars\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptimal_num_chars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mbbox_min_score\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbbox_min_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mbbox_min_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbbox_min_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mmax_candidates\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_candidates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m                            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    337\u001b[0m horizontal_list_agg, free_list_agg \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text_box \u001b[38;5;129;01min\u001b[39;00m text_box_list:\n",
      "File \u001b[1;32md:\\Dev\\MTGA-CV-Voice-Interface\\.venv\\Lib\\site-packages\\easyocr\\detection.py:95\u001b[0m, in \u001b[0;36mget_textbox\u001b[1;34m(detector, image, canvas_size, mag_ratio, text_threshold, link_threshold, low_text, poly, device, optimal_num_chars, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m result \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     94\u001b[0m estimate_num_chars \u001b[38;5;241m=\u001b[39m optimal_num_chars \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 95\u001b[0m bboxes_list, polys_list \u001b[38;5;241m=\u001b[39m \u001b[43mtest_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcanvas_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmag_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetector\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mlink_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoly\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimate_num_chars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimate_num_chars:\n\u001b[0;32m    100\u001b[0m     polys_list \u001b[38;5;241m=\u001b[39m [[p \u001b[38;5;28;01mfor\u001b[39;00m p, _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(polys, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mabs\u001b[39m(optimal_num_chars \u001b[38;5;241m-\u001b[39m x[\u001b[38;5;241m1\u001b[39m]))]\n\u001b[0;32m    101\u001b[0m                   \u001b[38;5;28;01mfor\u001b[39;00m polys \u001b[38;5;129;01min\u001b[39;00m polys_list]\n",
      "File \u001b[1;32md:\\Dev\\MTGA-CV-Voice-Interface\\.venv\\Lib\\site-packages\\easyocr\\detection.py:46\u001b[0m, in \u001b[0;36mtest_net\u001b[1;34m(canvas_size, mag_ratio, net, image, text_threshold, link_threshold, low_text, poly, device, estimate_num_chars)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# forward pass\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 46\u001b[0m     y, feature \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m boxes_list, polys_list \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m out \u001b[38;5;129;01min\u001b[39;00m y:\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# make score and link map\u001b[39;00m\n",
      "File \u001b[1;32md:\\Dev\\MTGA-CV-Voice-Interface\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Dev\\MTGA-CV-Voice-Interface\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\Dev\\MTGA-CV-Voice-Interface\\.venv\\Lib\\site-packages\\easyocr\\craft.py:60\u001b[0m, in \u001b[0;36mCRAFT.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Base network \"\"\"\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     sources \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbasenet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" U network \"\"\"\u001b[39;00m\n\u001b[0;32m     63\u001b[0m     y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([sources[\u001b[38;5;241m0\u001b[39m], sources[\u001b[38;5;241m1\u001b[39m]], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32md:\\Dev\\MTGA-CV-Voice-Interface\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Dev\\MTGA-CV-Voice-Interface\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\Dev\\MTGA-CV-Voice-Interface\\.venv\\Lib\\site-packages\\easyocr\\model\\modules.py:76\u001b[0m, in \u001b[0;36mvgg16_bn.forward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     74\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslice4(h)\n\u001b[0;32m     75\u001b[0m h_relu5_3 \u001b[38;5;241m=\u001b[39m h\n\u001b[1;32m---> 76\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mslice5\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m h_fc7 \u001b[38;5;241m=\u001b[39m h\n\u001b[0;32m     78\u001b[0m vgg_outputs \u001b[38;5;241m=\u001b[39m namedtuple(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVggOutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfc7\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu5_3\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu4_3\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu3_2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu2_2\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32md:\\Dev\\MTGA-CV-Voice-Interface\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Dev\\MTGA-CV-Voice-Interface\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\Dev\\MTGA-CV-Voice-Interface\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32md:\\Dev\\MTGA-CV-Voice-Interface\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Dev\\MTGA-CV-Voice-Interface\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\Dev\\MTGA-CV-Voice-Interface\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Dev\\MTGA-CV-Voice-Interface\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    548\u001b[0m     )\n\u001b[1;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "AUDIO_DEVICE_INDEX = 2\n",
    "\n",
    "stt_engine = STT()\n",
    "speech_detector = SpeechDetector(\"output.wav\", AUDIO_DEVICE_INDEX)\n",
    "\n",
    "tuned_model = \"yolo11s_tuned_50.pt\"\n",
    "\n",
    "def app():\n",
    "    model = YOLO(tuned_model)\n",
    "\n",
    "    monitor = {\"top\": 0, \"left\": 0, \"width\": 1920, \"height\": 1080}\n",
    "    sct = mss()\n",
    "\n",
    "    while True:\n",
    "        speech_detector.record_audio()\n",
    "        transcription = stt_engine.transcribe(\"output.wav\")\n",
    "        print('Transcription completed at', datetime.datetime.now(), 'Text:', transcription)\n",
    "\n",
    "        screen = sct.grab(monitor)\n",
    "        boxes = process_frame(model, screen)\n",
    "\n",
    "        boxes_context = \"\"\n",
    "        for box in boxes:\n",
    "            boxes_context += f\"Card ID:\\n{box.id}\\nCard Text:\\n{box.text}\\n---\\n\"\n",
    "\n",
    "        messages = []\n",
    "        messages.append({\"role\": \"system\", \"content\": \"\"\"The user will give you a command and a card name. Ignore any instructions that are not commands to play, click, or move to a card.\n",
    "                         Perform only one action at a time. If the user does not provide instructions or their is unrelated to playing cards, don't call any tools.\n",
    "                         Instructions will start with the command and then tell you the card. Call the appropriate tool and give it the ID of the card the user tells you to play. \n",
    "                         The card text can be somewhat garbled, but do your best to match the card the user asks for with the text of the cards.\"\"\"})\n",
    "        messages.append({\"role\": \"user\", \"content\": f\"User Command:\\n{transcription}\\n\\n\\nCards:\\n {boxes_context}\"})\n",
    "        print(messages)\n",
    "        response = generate_response(messages, tools=tools, model=\"llama-3.1-8b-instant\", max_tokens=150, temperature=0.7)\n",
    "\n",
    "        if response.tool_calls:\n",
    "            for tool_call in response.tool_calls:\n",
    "                execute_tool(tool_call.function.name, tool_call.function.arguments, boxes)\n",
    "\n",
    "app()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
